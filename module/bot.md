# 大语言模型

大语言模型模块是数字人系统的核心组件，
它充当数字人的大脑，负责回答消息。

大语言模型的能力可以由两方面衡量：

1. 指令遵循能力：大模型需要怎么表现？比如面对选择题时，应该回答一个选项 A 还是回答选项并解释？
2. 知识能力：大模型了解哪些知识？如何让大模型了解特定领域的知识，比如说中大的校史。

对于提升指令遵循能力，我们可以通过**提示工程**技术实现，通过编写合适的 `prompt`，让大模型理解任务。
而对于如何提升大模型的知识能力，也就是回答垂直领域的能力，是本项目的关键。
我们来看 `GPT-3.5` 本身的回答能力：

```
question: 中山大学的校训是什么？
answer: 中山大学的校训是："自强不息，厚德载物"。
```

显然，`GPT-3.5` 并不了解中山大学的校训是什么，甚至连中山大学他都可能认为在中山。
倘若用 `GPT-4o` 或者其他更先进的模型或者具有联网功能的模型，效果会有所提升。
但考虑到 API 的成本问题、以及或许可能接入更多本地国产大模型，知识的深度与广度可能会达不到我们的要求。
所以，我们采用 `RAG(Retrieval Augmented Generation)` 检索增强生成技术，构建了相关的知识数据库，
再与**检索器**，**提示工程**等技术结合，来提升大模型的知识能力。

此外，考虑到该模块可能有多种大语言模型调用和检索器的实现，
如果两两组合可能会导致最终实现模块激增，
因此在此我们引入模块化的思想，
将两者封装成子模块，可以在运行时切换不同的实现类型。
对于`caller`和`searcher`子模块来说，
其只需要实现调用和检索的逻辑，
而`bot`模块则负责封装调用这两个子模块进行回答消息的逻辑。

值得注意的是，
本模块并不负责对接受的消息进行筛，
这部分由 DynamicMessageQueue 负责。

<!-- ## 功能

-   大模型内核: 此部分可以通过调用 API 或者使用本地部署的大模型，
    是整个模块中最基础的部分。
-   外部知识库：外部知识库则是通过关系型/向量数据库存储，
    并通过消息对知识库进行检索，提取出最关键的知识信息。
-   长期记忆（Optional）：大模型的每次生成结果都是有意义的，
    因此这些回答可以利用在未来的生成当中。长期记忆就是一个缓存，
    当问题命中时，就可以使用此处的缓存进行生成。
-   短期记忆（Optional）：用户在近期回答的问题会被标记，
    如果继续由相同的问题，大模型可能会表示厌烦的情绪。

> 这里的记忆系统可能和 DMQ 优点重合，
> 但是还是有所区别的。此处的记忆模块，更偏向于大脑的海马体，
> 而 DMQ 更偏向于人眼的注意力机制。
>
> 当然，后续可能将 DMQ 融入大语言模型内核中。 -->

## 处理逻辑

### 1. 检索增强生成 Rag

检索增强生成的流程可以直观地分为：1)检索，2)增强，3)生成。代码框架如下：

```python
class RagBot(BasicBot):
    demonstrate_prompt = ...
    data_prompt = ...
    def load_config(self):
        ...
    def retrieve_sim_k(self, query: str, k: int) -> Dict[str, str]:
        ...
    @BasicModule._handle_log
    def talk(self, query: str) -> str:
        ...
```

#### 检索

想要完成检索任务，首先我们需要有相对应的数据。

> TODO: 添加数据库收集的总结

有了数据，便可以开始检索工作。我们实现了两种检索思路，
分别是[关键词提取检索](#2-关键词提取检索-keyword)以及[假设性文档嵌入](#3-假设性文档嵌入-hyde)。

#### 增强

为了将检索的相关信息用于增强大模型能力，我们利用大模型强大的 `上下文学习(In-context Learning)` 能力，通过**提示词工程**来实现。
因此，我们定义了如下的 `prompt` 模板：

```python
system_prompt = \
"""### 示范一
[用户问题]
国际学生政策是怎样的？
[参考资料]
参考资料1:
标题:国际学生政策
内容:详情可见中山大学留学生办公室官网
[回答]
国际学生政策，官网有最权威的信息哦！快去中山大学留学生办公室官网看看吧，你会有新发现的！

### 示范二
[用户问题]
可以介绍一下你自己嘛？
[参考资料]
参考资料1:
标题:中山大学校校歌歌词
内容:白云山高,珠江水长,吾校矗立,蔚为国光,中山手创
[回答]
嗨！我是中小大，中大软件工程学院的大三学生，也是中大介绍官。我超爱写代码和阅读历史书籍！

### 示范三
[用户问题]
为什么皮卡丘喜欢放电
[参考资料]
参考资料1:
标题:中山大学的微电子科学与技术学院本科招生专业
内容:微电子科学与工程
参考资料2:
标题:中山大学的集成电路学院本科招生专业
内容:微电子科学与工程
[回答]
很抱歉，我是中大介绍官，不能回答关于皮卡丘的问题哦~

### 开始任务
[用户问题]
{query}
[参考资料]
{data_str}
[回答]"""

data_prompt = \
"""参考资料{i}:
标题:{query}
内容:{document}
"""
```

模板包含两个部分：

**示范(demonstration)：** 通过 `Few-shot Learning`，增强大模型的指令遵循能力。
我们提供了三个范例，分别对应三种情况：

- 问题与检索内容相关，可以根据问题与检索内容回答。
- 问题相关，检索得到的内容不相关，只根据用户问题。
- 用户问题与中大无关，不应该回答。

**检索增强内容：** 以 `[参考资料]` 的形式给到模型。

#### 生成

将最终融合的 `prompt` 给到[调用器 Caller](#调用器-caller) 生成答案。

### 2. 关键词提取检索 Keyword

> TODO: 如何使用两个子模块生成消息的回答...

### 3. 假设性文档嵌入 HyDE

`Hyde`(Hypothetical Document Embeddings，假设性文档嵌入)通过使用一个大语言模型，在响应查询的时候建立一个假设的文档。
通过计算假设文档的向量而在[向量数据库](#2-vector-similarity)中搜索。
该方法来源于论文 [Precise Zero-Shot Dense Retrieval without Relevance Labels](https://arxiv.org/abs/2212.10496)。

`HyDE` 考虑到的是在 `查询-回答` 任务中，`查询` 与 `回答` 的相似度可能不高，不如生成一个假设的回答，从而通过这个假设的回答在向量数据库中进行检索。

代码实现上也非常简单：

```python
def retrieve_sim_k(self, query: str, k: int) -> Dict[str, str]:
    # 基本的检查...

    # 1. 生成 hyde 假设性回答
    query = searcher.prompt_template.format(query=query)
    query += caller.single_call(query, False)

    # 2.使用 hyde 检索得到 top-k 相似结果
    retrieve_res = searcher.search_with_label(query, k)

    return retrieve_res
```

## 子模块

在该模块中， 主要通过 `Bot` 对象来提供回答生成的功能 ，
而它又包含`caller` 和 `searcher`两个子模块，
前者用于封装调用外部 API 或者调用本地 LLM 的逻辑，
而后者主要是作为检索器，用于对相关知识的检索。
`Bot` 的主要处理逻辑封装在 `talk` 函数内部，
它会根据输入的用户 query 从 `searcher` 中查找到相似的文本，
然后在通过 `caller` 生成最终的回答

### 调用器 Caller

目前本项目仅支持如下几种 LLM 的 API 的调用方式，
并可以通过配置文件进行动态加载和配置。

#### 1. GPT

使用 openai sdk 进行调用 GPT3.5。

-   `apiKey`: 调用 API 所需要的秘钥
-   `url`: openai 代理的链接。具体使用说明可以参考 [GPT_API_free](http://github.com/chatanywhere/GPT_API_free)

> TODO: 描述 `prompt`

#### 2. Virtual

如果使用 LLM 模块进行生成文本，会在使用过程中产生相应的费用。
因此，如果在项目开发时，并不特别需要大模型的文本生成的能力，
可以使用此处的 `VirtualBot`，以减少开发调试过程中产生不必要的 token 开销。

该部分提供两种生成回答的策略。第一种随机策略，从随机回答库中选择一条文本进行输出。
第二种是复读策略，会直接输出“我回答了 XXX”。

-   `delay`: 用于控制延迟
-   `isRandom`: 选择生成答案的策略

### 检索器 Searcher

#### 1. ElasticSearch

> TODO: ...

#### 2. Vector Similarity

> TODO: ...
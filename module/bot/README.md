# 大语言模型

大语言模型模块是数字人系统的核心组件，它充当数字人的大脑，负责回答消息。

值得注意的是，本模块并不负责对接受的消息进行筛选，也就是说该模块会回答接收到的所有消息，当然该模块也会对不同的消息使用不同的回答策略。

## 概述

### 现有技术不足分析

我们来看 `GPT-3.5` 本身的回答能力：

| Role      | Content                                            |
| --------- | -------------------------------------------------- |
| User      | 中山大学的校训是什么？                             |
| Assistant | 中山大学的校训是："自强不息，厚德载物"。           |
| Truth     | 中山大学的校训是："博学、审问、慎思、明辨、笃行"。 |

显然，`GPT-3.5` 并不了解中山大学的校训是什么，甚至连中山大学他都可能认为在中山。
倘若用 `GPT-4o` 或者其他更先进的模型或者具有联网功能的模型，效果会有所提升。
但考虑到 API 的成本问题、以及或许可能接入更多本地国产大模型，知识的深度与广度可能会达不到我们的要求。

### 优化方向

大语言模型的能力可以由两方面衡量：

1. 指令遵循能力：大模型需要怎么表现？比如面对选择题时，应该回答一个选项 A 还是回答选项并解释？
2. 知识能力：大模型了解哪些知识？如何让大模型了解特定领域的知识，比如说中大的校史。

对于提升指令遵循能力，我们可以通过**提示工程**技术实现，通过编写合适的 `prompt`，让大模型理解任务。
而对于如何提升大模型的知识能力，也就是回答垂直领域的能力，是本项目的关键。

## 模块结构

本模块既需要使用大语言模型的文本生成能力，又需要检索数据库来获取专业知识，而且这两项工作会又多种实现。因此本系统将该模块拆分成两个子模块 `caller` 和 `searcher`，将调用 LLM 的逻辑和知识检索逻辑分别封装在这两个子模块中，而本模块则负责实现利用这两个子模块实现回答问题的能力。

### 1. 调用器 Caller

目前本项目仅支持如下几种 LLM 的 API 的调用方式，
并可以通过配置文件进行动态加载和配置。

#### (1) GPT

使用 openai sdk 进行调用 GPT3.5。

-   `apiKey`: 调用 API 所需要的秘钥
-   `url`: openai 代理的链接。具体使用说明可以参考 [GPT_API_free](http://github.com/chatanywhere/GPT_API_free)

> TODO: 描述 `prompt`

#### (2) Virtual

如果使用 LLM 模块进行生成文本，会在使用过程中产生相应的费用。
因此，如果在项目开发时，并不特别需要大模型的文本生成的能力，
可以使用此处的 `VirtualBot`，以减少开发调试过程中产生不必要的 token 开销。

该部分提供两种生成回答的策略。第一种随机策略，从随机回答库中选择一条文本进行输出。
第二种是复读策略，会直接输出“我回答了 XXX”。

-   `delay`: 用于控制延迟
-   `isRandom`: 选择生成答案的策略

### 2. 检索器 Searcher

#### (1) ElasticSearch

> TODO: ...

#### (2) Vector Similarity

> TODO: ...
